{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "a669aab8-cb37-46fd-8f41-6a988c647d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from numpy.random import multinomial\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "baa262f7-0fb4-4ce5-8c03-c298ef5cc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "813d0c4e-1133-46e9-86e0-0ccf351b7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startchar: \"<\"\n",
      "Endchar: \">\"\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "startchar = \"<\"\n",
    "endchar = \">\"\n",
    "print(f'Startchar: \"{startchar}\"')\n",
    "print(f'Endchar: \"{endchar}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e8aad09c-2654-4b3d-afb9-2654e9a1b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file: str, column_name: str):\n",
    "    dataset = pd.read_csv(file)\n",
    "    dataset = dataset[column_name].to_numpy()\n",
    "    return dataset\n",
    "\n",
    "def prep_data(rawdata: np.ndarray, n=4): \n",
    "    for i, sample in tqdm(enumerate(rawdata)):\n",
    "        sample = ((startchar + \" \")*n) + sample + ((\" \" + endchar)*n)\n",
    "        rawdata[i] = sample\n",
    "\n",
    "    print(rawdata[0])\n",
    "    \n",
    "    return rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "75a89c57-d7ea-4fda-85b3-5b67d4d1941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(open(\"datasets/Emusk_2021_tweets.csv\", errors='ignore'), \"Text\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "597a35f1-aceb-4dcf-a012-25b94e7b2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2993it [00:00, 376813.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< < @PPathole Dojo isn’t needed, but will make self-driving better. It isn’t enough to be safer than human drivers, Autopilot ultimately needs to be more than 10 times safer than human drivers. > >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = prep_data(data, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ba293367-f7df-40b9-9b0a-65cccf474264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ngrams(prepped_data: np.ndarray, n=4):\n",
    "    unique_ngrams = set()\n",
    "    \n",
    "    for sample in tqdm(prepped_data):\n",
    "        words = sample.split()\n",
    "        for i in range(len(words) - (n-1)):\n",
    "            ngram = \" \".join(words[i:i+n])\n",
    "            unique_ngrams.add(ngram)\n",
    "    print(f\"Number of unique {n}-grams:\", len(unique_ngrams))\n",
    "    return unique_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "b05e96c8-0df4-427e-b124-839c04aab37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2993/2993 [00:00<00:00, 163713.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique 2-grams: 29596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_ngrams = get_unique_ngrams(data, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "88e3c207-9df3-40f0-98b1-0f73dadb5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngram_appearances(prepped_data: \n",
    "                            np.ndarray, \n",
    "                            unique_ngrams: set, \n",
    "                            n=4,\n",
    "                            smoothing_factor=1):\n",
    "    \n",
    "    ngram_counts = defaultdict(dict)\n",
    "    total_unique_ngram_count = len(unique_ngrams)\n",
    "    total_word_count = len(unique_words)\n",
    "    \n",
    "    for sample in tqdm(prepped_data):\n",
    "        words = sample.split(\" \")\n",
    "        wordcount = len(words)\n",
    "        \n",
    "        for i in range(wordcount - n):\n",
    "            ngram = \" \".join(words[i:i+n])\n",
    "            next_word = words[i+n]\n",
    "            \n",
    "            if next_word in ngram_counts[ngram]:\n",
    "                ngram_counts[ngram][next_word] += 1\n",
    "            else:\n",
    "                ngram_counts[ngram][next_word] = smoothing_factor # smoothing_factor may not be working correctly\n",
    "                      \n",
    "    return ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5222dad3-b5e2-452d-9944-2ce97cecab76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2993/2993 [00:00<00:00, 117805.15it/s]\n"
     ]
    }
   ],
   "source": [
    "ngram_counts = count_ngram_appearances(data, unique_ngrams, n=n, smoothing_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "3e98e838-0a91-4995-ba72-fcfd527c816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_probabilities(ngram_counts: defaultdict(dict)):\n",
    "    # calculate probabilities\n",
    "    # key = ngram\n",
    "    # value = dict { nextword: probability }\n",
    "    #print(sum(list(ngram_probabilities.items())[0][1].values()))\n",
    "    ngram_probabilities = ngram_counts\n",
    "\n",
    "    for ngram, next_words in tqdm(ngram_probabilities.items()):\n",
    "        total_count = sum(next_words.values())\n",
    "        for next_word in next_words:\n",
    "            ngram_probabilities[ngram][next_word] /= total_count\n",
    "       \n",
    "    return ngram_probabilities              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "f26e4869-0ac5-43fa-a9d9-82fe74e744ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29529/29529 [00:00<00:00, 2019890.13it/s]\n"
     ]
    }
   ],
   "source": [
    "ngram_probs = calculate_ngram_probabilities(ngram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "e10ddc86-7aa4-4dc0-9a64-1fd850770789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(ngram_probabilities: defaultdict(dict)):\n",
    "\n",
    "    out = []\n",
    "    for i in range(n): out.append(\"<\")\n",
    "    lastn = ' '.join(out[-n])\n",
    "\n",
    "    while True:\n",
    "        lastn = ' '.join(out[-n:])\n",
    "        #print(lastn)\n",
    "        probs = ngram_probs[lastn]\n",
    "        idx = multinomial(1, [*probs.values()]).argmax()\n",
    "        word = [*probs.keys()][idx]\n",
    "        if word == endchar: break\n",
    "        out.append([*probs.keys()][idx])\n",
    "        \n",
    "    print(' '.join(out[n:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "f8472690-cbbb-4ebe-863c-46bb145f8cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceX launching satellite Doge-1 to the moon at all costs\n"
     ]
    }
   ],
   "source": [
    "gen = generate(ngram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "849924d4-f1e1-419d-a233-46e3ec48aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< < SpaceX launching satellite Doge-1 to the moon next year\n",
      "\n",
      "– Mission paid for in Doge\n",
      "– 1st crypto in space\n",
      "– 1st meme in space\n",
      "\n",
      "To the mooooonnn!!\n",
      "\n",
      "https://t.co/xXfjGZVeUW > >\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    if \"SpaceX launching satellite\" in d: print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
