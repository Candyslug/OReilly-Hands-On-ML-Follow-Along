{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17be233-cbc1-48a0-b249-7d34572e66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48088d79-ba48-4cee-9197-4a7b469c17ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.62313406  8.87720831  4.84001326]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((750, 3), (750,), (250, 3), (250,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 1000\n",
    "\n",
    "X, y = make_blobs(n_samples=m,\n",
    "                  n_features=3,\n",
    "                  shuffle=True,\n",
    "                  random_state=42)\n",
    "\n",
    "train_size = 750\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a7fb4f28-cd32-4ba4-ae91-66116055acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:   [-1.7134843 -5.1125574  6.2606854]\n",
      "Softmax:  [3.44118191e-04 1.14949935e-05 9.99644399e-01]\n",
      "Loss:     0.00035565728\n",
      "\n",
      "\n",
      "Logits:\n",
      " tensor([[ 2.4593, -0.9181,  6.0376],\n",
      "        [-1.2193,  1.2717, -5.5731],\n",
      "        [ 1.9715, -0.9329,  6.3642],\n",
      "        [-0.6470, -4.9998,  7.2019],\n",
      "        [ 0.9929, -2.1822,  7.1968],\n",
      "        [-1.7135, -5.1126,  6.2607],\n",
      "        [ 0.3726, -1.4776,  6.0889],\n",
      "        [-1.4856, -4.9399,  6.3059],\n",
      "        [ 1.8181, -1.5287,  6.3792],\n",
      "        [-0.1748, -3.9132,  5.9726],\n",
      "        [-1.0460, -5.4438,  6.8412],\n",
      "        [ 1.8234, -1.5400,  7.9136],\n",
      "        [ 2.0170, -1.0839,  5.7875],\n",
      "        [-0.4587, -5.0183,  6.1394],\n",
      "        [ 2.1092, -1.1774,  6.0311]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Softmax torch.Size([15, 3]):\n",
      " tensor([[2.7139e-02, 9.2640e-04, 9.7193e-01],\n",
      "        [7.6420e-02, 9.2260e-01, 9.8257e-04],\n",
      "        [1.2207e-02, 6.6876e-04, 9.8712e-01],\n",
      "        [3.9003e-04, 5.0199e-06, 9.9961e-01],\n",
      "        [2.0172e-03, 8.4300e-05, 9.9790e-01],\n",
      "        [3.4412e-04, 1.1495e-05, 9.9964e-01],\n",
      "        [3.2792e-03, 5.1553e-04, 9.9621e-01],\n",
      "        [4.1308e-04, 1.3057e-05, 9.9957e-01],\n",
      "        [1.0339e-02, 3.6387e-04, 9.8930e-01],\n",
      "        [2.1343e-03, 5.0781e-05, 9.9781e-01],\n",
      "        [3.7540e-04, 4.6188e-06, 9.9962e-01],\n",
      "        [2.2596e-03, 7.8227e-05, 9.9766e-01],\n",
      "        [2.2499e-02, 1.0126e-03, 9.7649e-01],\n",
      "        [1.3611e-03, 1.4246e-05, 9.9862e-01],\n",
      "        [1.9404e-02, 7.2533e-04, 9.7987e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Loss:\n",
      " tensor(2.5617, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "\n",
      "tensor([[3.4412e-04, 1.1495e-05, 9.9964e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(2.5617, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def printt(x): print(['{:f}'.format(i) for i in x.detach().numpy()])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    nn.Linear(in_features=3, out_features=3))\n",
    "    #nn.Softmax(dim=0))\n",
    "\n",
    "\n",
    "    \n",
    "X_train_tensor = torch.from_numpy(X_train).type(torch.float32)\n",
    "y_train_tensor = torch.Tensor(y_train).type(torch.long)\n",
    "\n",
    "\n",
    "# single\n",
    "\n",
    "i = 5\n",
    "\n",
    "samples = X_train_tensor[i].unsqueeze(0)\n",
    "\n",
    "preds = layers(samples)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = loss_fn(preds, y_train_tensor[i].unsqueeze(0))\n",
    "\n",
    "print(\"Logits:  \", preds.detach().numpy().squeeze())\n",
    "print(\"Softmax: \", torch.softmax(preds, dim=1).detach().numpy().squeeze())\n",
    "print(\"Loss:    \", loss.detach().numpy())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# multi\n",
    "\n",
    "i = 15\n",
    "\n",
    "samples = X_train_tensor[:i]\n",
    "labels = y_train_tensor[:i]\n",
    "logits = layers(samples)\n",
    "loss = loss_fn(logits, labels)\n",
    "\n",
    "print(\"Logits:\\n\", logits)\n",
    "print(f\"\\nSoftmax {logits.shape}:\\n\", torch.softmax(logits, dim=1))\n",
    "print(\"\\nLoss:\\n\", loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.softmax(preds, dim=1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05267b2c-7e82-4b4c-8b9e-083c0a929492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b6da-88c8-46fe-b6c1-5e585be2ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a15b44-4976-4ddf-b167-2028c4a99dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
